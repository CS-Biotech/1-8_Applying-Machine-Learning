{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zbhQGzDhw-X"
   },
   "source": [
    "# Week 8 - Applying Machine Learning\n",
    "# Tutorial Module\n",
    "\n",
    "This week, we will be working on a case study that utilizes machine learning (ML) on a genetics dataset. The goal of this module is to have you go through the ML pipeline to identify and classify types of cancer in patient data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYXSrJa5ifT-"
   },
   "source": [
    "### ML Pipeline\n",
    "\n",
    "As a reminder, a Machine Learning pipeline typically involves 4 steps:\n",
    "\n",
    "1. Data Preparation: In this step, we obtain the relevant data for the task we are trying to perform.\n",
    "2. Data Exploration: We then analyze the data at hand to manually find potentially interesting patterns.\n",
    "3. Model Training: Once we have explored our data and manually identified potential trends and patterns, we can train (aka fit) a machine learning model. Ideally, the ML model will pick up patterns we have missed and will be able to outperform the rules we discover.\n",
    "4. Model Evaluation: To confirm if the model picked up useful trends, we will use a variety of metrics to evaluate how well the model does at our task.\n",
    "\n",
    "![fcall](fcall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOsT968liKIf"
   },
   "source": [
    "### Gene Expression Data for Acute Leukemia Patients\n",
    "In this module, we will analyze gene expression data for acute leukemia patients. Leukemia is a form of cancer that impacts the blood and bone marrow, interfering with the normal production and function of healthy blood cells. Within the bone marrow, blood stem cells, known as hematopoietic stem cells, generate different types of blood cells. Leukemia arises when these stem cells produce abnormal white blood cells, crowding out healthy cells and disrupting their functions. As a result, individuals with leukemia may become more prone to infections, experience anemia, or bleed easily.\n",
    "\n",
    "Given its severity, it would be nice to be able to identify the type of leukemia a patient may have. To do this, [Golub et al. (1999)](https://pubmed.ncbi.nlm.nih.gov/10521349/) collected gene expression data from patients and aimed to identify whether or not patients had either acute myeloid leukemia (AML) or acute lymphoblastic leukemia (ALL). Our goal is to use this data to create a classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaYwUnQVl6lJ"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "![fc1](fc1.png)\n",
    "\n",
    "Like in our previous datasets, the data has already been prepared for us. Detailed preparation steps can be found at [this link](https://www.kaggle.com/code/selinyang/gene-expression-data-for-acute-leukemia-patients).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isoufL5jl0LE"
   },
   "source": [
    "---\n",
    "**Q*1: Read in `'gene_expression_data.csv'`. Assign the `'cancer'` column to `y` and the rest of the columns to `X`.**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMcjMCNYhtIW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# YOUR CODE HERE\n",
    "data = \n",
    "y = \n",
    "X = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JABO33RzAcdU"
   },
   "source": [
    "---\n",
    "Each column in `X` corresponds to a certain level of gene expression, and each row is a patient. The `y` contains the type of cancer the patient has: `\"ALL\"` or `\"AML\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_x_WMVGLnIeM"
   },
   "source": [
    "---\n",
    "**Q*2: Binarize `y` by assigning `ALL` to 0 and `AML` to 1.**\n",
    "\n",
    "> Hint: consider using the `map()` function that was used a few times since Week 5.\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0-KZpCQnrBH"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "y =\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NEthVg8mSh0"
   },
   "source": [
    "---\n",
    "### Data Exploration\n",
    "\n",
    "![fc2](fc2.png)\n",
    "\n",
    "\n",
    "Before we dive into training an ML Model, we will first manually explore the data to see if we can identify ways to distinguish between the two classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGdg5CRKn8Qn"
   },
   "source": [
    "---\n",
    "**Q*3: How many genes (features) are in the dataset?**\n",
    "\n",
    "<!-- > Hint: Look at week 3 Question 5 on how to subset dataframes. -->\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VkxbP1eoIix"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_Q8FkAfn7v7"
   },
   "source": [
    "---\n",
    "**Q*4: Subset the data into two different dataframes, one with all \"AML\" cases and one with \"ALL\" cases. What percentage of patients have \"AML\"?**\n",
    "\n",
    "> Hint: Look at week 3 Question 5 on how to subset dataframes.\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpKREN6womdk"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Subset the data\n",
    "X_aml = \n",
    "X_all = \n",
    "\n",
    "# Calculate the percentage of patients with AML\n",
    "percentage_aml = \n",
    "print(percentage_aml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEn21o5bol7g"
   },
   "source": [
    "---\n",
    "**Q*5: Without using ML, visualize and analyse the data and try to construct 1-2 manual rules that may distinguish between the two types of cancer. What is the accuracy of your rules?**\n",
    "\n",
    "> Hint: Refer to Week 5 Pre-module on how to make rules.\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3v-Ar0AbpiPe"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Write your rules here and complete the rest of the code\n",
    "\n",
    "\n",
    "\n",
    "true_positives = \n",
    "false_positives = \n",
    "true_negatives = \n",
    "false_negatives = \n",
    "\n",
    "accuracy = \n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uniRgrKqH5W"
   },
   "source": [
    "---\n",
    "### Model Training\n",
    "\n",
    "![fc3](fc3.png)\n",
    "\n",
    "Now, let's train an ML model to perform this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xl4oVIbCpiXA"
   },
   "source": [
    "---\n",
    "**Q*6: Split the data into training sets (`X_train` and `y_train`) and testing sets (`X_test` and `y_test`).**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pctes8OppG-"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Import the correct function (refer to Pre-module)\n",
    "\n",
    "\n",
    "# Split the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kJFaYkWqRjX"
   },
   "source": [
    "---\n",
    "In the previous modules, you learned about 4 different models. In the sections below, you will tune and train two different models. The first one will be Logistic Regression, and the second will be Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrVVu8NwqgT9"
   },
   "source": [
    "---\n",
    "**Q*7: Use grid search to test combinations of at least 2 hyperparameters (but feel free to add more) for Logistic Regression. Fit using the training set, predict using the test set, and calculate accuracy.**\n",
    "\n",
    "> Hint: Refer to Week 6.\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTWzTgB9rLBJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Step 1: Initialize hyperparameter arrays \n",
    "# YOUR CODE HERE\n",
    "C_values = ...  # Regularization strength from 10^-4 to 10^4\n",
    "penalty_values = ...     # L1 (Lasso) or L2 (Ridge) regularization\n",
    "\n",
    "# Step 2: Manually iterate over Hyperparameter Combinations and retrieve the combination that performs best for accuracy\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Loop over all combinations of hyperparameters\n",
    "# YOUR CODE HERE\n",
    "for ...\n",
    "    for ...\n",
    "        print(f\"Training model with penalty={penalty}, C={C}\")\n",
    "        \n",
    "        # Initialize the Logistic Regression model with current hyperparameters\n",
    "        model = ...\n",
    "        \n",
    "        # Train the model\n",
    "        ...\n",
    "        \n",
    "        # Predict on the test set\n",
    "        ...\n",
    "        \n",
    "        # Evaluate accuracy\n",
    "        accuracy = ...\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Update the best model if we find a better one\n",
    "        if ...\n",
    "            \n",
    "\n",
    "\n",
    "# Step 3: Output the Best Hyperparameters and Model Performance\n",
    "print(\"\\nBest hyperparameters:\", best_params)\n",
    "print(f\"Best accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F58F_bNFuns2"
   },
   "source": [
    "---\n",
    "**Q*8: Using the best hyperparameters found, train a new Logistic Regression model on all the training data.**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaciwUUhwFjP"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a new model\n",
    "lr = ...\n",
    "\n",
    "# Train the model using the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vfn7JBiUwKkq"
   },
   "source": [
    "---\n",
    "### Model Evaluation\n",
    "\n",
    "![fc4](fc4.png)\n",
    "\n",
    "Now that we have trained our model, let's see how well it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF8WvH69wRvf"
   },
   "source": [
    "---\n",
    "**Q*9: Make predictions on the training and test sets for the Logistic Regression model.**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gHaOUAkwY1O"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE \n",
    "# Make predictions for the training data\n",
    "\n",
    "\n",
    "# Make predictions for the testing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVh59GtJwZKW"
   },
   "source": [
    "---\n",
    "**Q*10: What are the train and test accuracy, precision, recall, and F1-score? Do you think the model is underfitting, overfitting, or neither? Why?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLlAg7RvwnpG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Evaluation metrics for the train set\n",
    "acc = ...            #TODO: complete this line\n",
    "precision = ...      #TODO: complete this line\n",
    "recall = ...         #TODO: complete this line\n",
    "f1 = ...             #TODO: complete this line\n",
    "\n",
    "eval_train = pd.Series({\n",
    "    \"Accuracy\": acc,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1-Score\": f1\n",
    "})\n",
    "\n",
    "# Evaluation metrics for test set\n",
    "acc = ...        #TODO: complete this line\n",
    "precision = ...  #TODO: complete this line\n",
    "recall = ...     #TODO: complete this line\n",
    "f1 = ...         #TODO: complete this line\n",
    "\n",
    "eval_test = pd.Series({\n",
    "    \"Accuracy\": acc,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1-Score\": f1\n",
    "})\n",
    "\n",
    "print(f\"Model: LogisticRegression\")\n",
    "print(f\"\\nEvaluation metrics for train set:\\n\",eval_train)\n",
    "\n",
    "print(f\"Model: LogisticRegression\")\n",
    "print(f\"\\nEvaluation metrics for test set:\\n\",eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga0Lj7JqwoZk"
   },
   "source": [
    "## **Graded Exercise: (9 marks)**\n",
    "\n",
    "**GQ*1: Repeat Questions 7-10 for Random Forest. (8 marks)**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for Random Forest\n",
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF0rSolvzxtO"
   },
   "source": [
    "##### **GQ*1-7: Use grid search to test combinations of at least 2 hyperparameters (but feel free to add more) for Random Forest. Fit using the training set, predict using the test set, and calculate accuracy (3pt).**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVT5-St-zzej"
   },
   "outputs": [],
   "source": [
    "# Step 1: Initialize hyperparameter arrays \n",
    "# YOUR CODE HERE\n",
    "n_estimators_values = ...  # Number of trees in the forest\n",
    "max_depth_values = ...     # Maximum depth of each tree\n",
    "\n",
    "# Step 2: Manually iterate over Hyperparameter Combinations and retrieve the combination that performs best for accuracy\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Loop over all combinations of hyperparameters\n",
    "# YOUR CODE HERE\n",
    "for ...\n",
    "    for ...\n",
    "        print(f\"Training model with n_estimators={n_estimators}, max_depth={max_depth}\")\n",
    "        \n",
    "        # Initialize the Random Forest model with current hyperparameters\n",
    "        model = ...  # Add a random_state for reproducibility\n",
    "        \n",
    "        # Train the model\n",
    "        ...\n",
    "        \n",
    "        # Predict on the test set\n",
    "        ...\n",
    "        \n",
    "        # Evaluate accuracy\n",
    "        accuracy = ...\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Update the best model if we found a better one\n",
    "        if ...\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Output the Best Hyperparameters and Model Performance\n",
    "print(\"\\nBest hyperparameters:\", best_params)\n",
    "print(f\"Best accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S85kpQLzzpK"
   },
   "source": [
    "##### **GQ*1-8: Using the best hyperparameters found, train a new Random Forest model on all the training data (1pt).**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzHExC59z1cr"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Create a new model\n",
    "rf = ...\n",
    "\n",
    "# Train the model using the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYuZHM2xz0uq"
   },
   "source": [
    "##### **GQ*1-9: Make predictions on the training and test sets for the Random Forest model (2pt).**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Brz92Mvhz2lX"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Make prediction for the training data\n",
    "\n",
    "\n",
    "# Make predictions for the testing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zI7NjT6z2rV"
   },
   "source": [
    "##### **GQ*1-10: What are the train and test accuracy, precision, recall, and F1-score? Do you think the model is underfitting, overfitting, or neither? Why? (2pt)?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pVr_QWEz3pU"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluation metrics for the train set\n",
    "acc = ...            #TODO: complete this line\n",
    "precision = ...      #TODO: complete this line\n",
    "recall = ...         #TODO: complete this line\n",
    "f1 = ...             #TODO: complete this line\n",
    "\n",
    "eval_train = pd.Series({\n",
    "    \"Accuracy\": acc,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1-Score\": f1\n",
    "})\n",
    "\n",
    "# Evaluation metrics for the test set\n",
    "acc = ...            #TODO: complete this line\n",
    "precision = ...      #TODO: complete this line\n",
    "recall = ...         #TODO: complete this line\n",
    "f1 = ...             #TODO: complete this line\n",
    "\n",
    "eval_test = pd.Series({\n",
    "    \"Accuracy\": acc,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1-Score\": f1\n",
    "})\n",
    "\n",
    "print(f\"Model: Random Forest\")\n",
    "print(f\"\\nEvaluation metrics for train set:\\n\",eval_train)\n",
    "\n",
    "print(f\"Model: Random Forest\")\n",
    "print(f\"\\nEvaluation metrics for test set:\\n\",eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAONeJXpzMGD"
   },
   "source": [
    "**GQ*2: Which model (Logistic Regression or Random Forest) performed better? (1pt)**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
